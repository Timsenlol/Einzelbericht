\chapter{Sprints}\label{app:Sprints}
\section{Sprint 0 24.01.2025 bis 21.02.2025}
Nach der Zusage der Verwaltung, dass wir das Projekt in der urspürnglich von uns beantragten Gruppe durchführen zu dürfen, setzten wir uns zeitnah mit Dr. Kötting in Verbindung. Hinsichtlich des Themas hatten wir noch Bedenken, da Dr Köttings initiale Projektidee, die er auch in der ersten Informationsveranstaltung dem Studiengang vorgestellt hatte uns allen nicht gefallen hatte. Im ersten Gesprächen stellte sich allerdings raus das Herr Dr. Kötting hier offen war das Thema anzupassen und daher beauftragte er uns mit der Ausarbeitung einer neuen Projektidee. Ihm war es wichtig, dass die ausgearbeitete Projektidee, Fragestellungen oder Probleme mit Hilfe von KI lösen kann.
Das Projektteam erarbeitete sich die Projektidee im Rahmen einer strukturierten Kreativitätsphase.
Hier wurde das "1-3-All"-Verfahren genutzt (angelehnt an das "1-2-4-All" Verfahren 
\cite{Desginthinking124}), um eine große Menge an Ideen zu entwickeln. Nach der Sammlung der Ideen,  stellte jede Person Ihre Ideen der Gruppe (3er Gruppe oder alle) vor, wo diese dann im Kollektiv diskutiert, verfeinert und gegeben falls zu mit anderen Ideen geclustert wurde. Abschließend hatte jeder Teilnehmer drei Stimmen um sie auf die erarbeiteten Ideen zu verteilen. Die drei Ideen mit den meisten Stimmen würden nochmal unsern Auftraggebern Dirk Kötting vorgestellt und gemeinsam diskutiert. Wichtige Faktoren waren hier der erwartbare Mehrwert für einen potenziellen Kunden und die technische Umsetzbarkeit.
Letztendlich hat sich die Projektgruppe für das Security Tool entschieden. Ausschlaggebend waren zum einem die Interessen und Kenntnisse unseres Auftraggeber, von dem dieses Projekt profitiert hat. Zum andern das dieses Projekt eine Lösungen für echte Probleme von mittelständischen Unternehmen anbietet. 
In einem anschließenden Treffen haben wir uns ein ein Codeverwaltung- und Projektmanagement-Tool geeinigt.  Für die Codeverwaltung fiel unsere Wahl auf Github, als eine der führenden Codeverwaltungsplattformen. Github ist grundsätzlich kostenlos. Ein weiterer Faktor waren die "GitHub Student Developer Packs" mit denen wir einen kostenlosen Zugang zu erweiterten Funktionen und kostenpflichtigen Angeboten erhielten (vgl \cite{github_student_pack}). 
Beim Projektmanagementtool fiel unsere Wahl auf Jira. Auch Jira ist ein im Mark etabliertes Tool im Bereich des Projektmanagement. Wir nutzen Jira zum verwalten unser Vorhaben in Form von Epics, darunter clusterten wir auch später die die jeweiligen Task, die wir in dem entsprechenden Sprint bearbeiten wollten. Für die Übersicht haben wir ein Kanban Board angelegt, wo die entsprechenden Vorhaben mit ihrem aktuellen Status für jedes Gruppenmitglied jederzeit über ihre eigenen Jira Zugänge einsehbar war. Ein wichtiger Punkt der für Jira gesprochen hatte war, dass unser Product Owner Christian Langer breites viel Erfahrung im Umgang mit Jira hatte. Er das Wissen über den Umgang mit dem Tool ins Projekt tragen.  Im nächsten Schritt habe ich mich um meine lokalen Entwicklungsumgebungen gekümmert. Da ich bereits viel Erfahrung mit den Entwicklungsumgebungen von Jetbrains hatte, wollte ich wieder auf diese setzen. Nach Recherche bin ich auf "Jetbrains Student Pack" gestoßen, welches Studenten erlaubt alle kostenpflichtigen Entwicklungsumgebungen kostenlos zu nutzen (vgl. \cite{jetbrains_student}). Initial installierte ich PyCharm und Intellij.
Innerhalb unser einzeln Workstreams haben wir nun die Anforderungen an die jeweiligen Module herausgearbeitet. Hierbei haben wir versucht aus den groben Epics, auf die wir uns mit Herrn Dr Kötting committet hatten, einzelne Anforderungen abzuleiten. Christian, Daniel und ich haben für das Phishing Modul im ersten Schritt ein grobes Ablaufdiagramm gezeichnet, um anschließend draus die einzelnen Anforderungen leichter erarbeiten zu können. Abschließend haben in der gesamten Projektgruppe die ausgearbeiteten Anforderungen vorgestellt und besprochen. Hier haben wir nochmal einige Anpassungen vorgenommen zum Beispiel hinsichtlich der zu auszuwertenden Parameter wie "Schwierigkeitsgrad". Diese Einstellung haben wir noch einigen Diskussionen zunächst verworfen.
Nachdem wir alle zufrieden mit den formulierten Anforderungen waren, haben wir diese auch nochmal unsern Auftraggeber vorgestellt um sicherzugehen, dass diese Anforderungen seinen Vorstellungen entsprechen. Dr. Dirk Kötting hat hier nochmal sehr gute Einwürfe gebracht und wir konnten die initialen Anforderungen nochmal verfeinern. Ein wichtige Anmerkung, war der Datenschutzgedanke und der Gedanke der Rechtssicherheit. Draus haben haben wir zum Beispiel die Anforderung abgeleitet, dass der Anwender vor der erstmaligen Nutzung des Moduls eine Nutzungsbedingung akzeptieren muss.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/erster_Wurf_Ablauf.png} 
    \caption{Erster Wurf für den Ablauf des Phishing-Workflows}
    \label{fig:architektur1}
\end{figure}
\section{Sprint 1 21.02.2025 bis 21.03.2025}
In diesem Sprint haben wir uns mit der grundsätzlichen Architektur innerhalb des Phishing Moduls beschäftigt. Zunächst haben wir uns gemeinsam auf die Strategie geeinigt eine eigene  KI zu schreiben die Phishingmails geniert. Unter dieser Bedingung haben wir geplant ein Spring Backend zu schreiben, welches orchestrierende Aufgaben übernimmt sowie ein Python Flask Backend, welches die KI selbst aufruft.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/EntwurfSprint1.png} 
    \caption{Entwurf der Modul Architektur im Sprint 1}
    \label{fig:architektur}
\end{figure}
Im ersten operativen Schritt habe ich das Grundgerüst des Springbootprojekts angelegt.Zu Erstellung des Projektes habe ich der Spring Initializr. Dieses kostenlose Tool ermöglicht eine geführte Erstellung der Projektstruktur. Nach Rücksprache mit Christian und Daniel haben wir uns für ein Maven Projekt in Kotlin entschieden. Maven.Die Punkte die für Maven gesprochen haben sind zum einem seine Leichtgewichtigkeit sowie meine Praxiserfahrung mit dem Buildtool. Dadurch konnte ich Christian und Daniel effizient in das Tool einarbeiten. Für Kotlin habe ich mich bewusst entschieden, denn ich wollte die Sprache im Rahmen des Projektes zu evaluieren und zu prüfen ob sie sich  eignet in meinen  Arbeitsprojekten eingesetzt zu werden. Kotlin ist eine deutlich moderene Sprache als Java und bietet einige Vorteile von denen wir auch im Rahmen unsres Projekts profitiert haben. 
\begin{itemize}
  \item \textbf{Null Saftey}: Variablen müssen explizit als "nullbar" deklariert werden. Das mindert die Gefahr von "NullPointerExceptions" erheblich. Schon während der Entwicklungsphase, hat sich dieses Feature als äußert wertvoll erwiesen. Zum einem haben wir nicht viele solcher Exceptions gehabt und wenn wir welche hatten kamen nur nullbare Variablen in Frage.
  \item \textbf{Kompakter Code}:Bolier plate Code wird drastisch reduziert. Wir konnten sehr viele Zeilen an Code sparen allein dadurch, dass Kotlin hier einfach modrner ist als Java. Zum Beispiel wird das arbeiten auf Listen deutlich vereinfacht. Wo man in Java mit einer externe Libary oder vielen If Else arbeiten muss, kann man in Kotlin auch komplexere Sachen in 2-3 Zeilen abbilden. 
\end{itemize}
Wir haben uns darüber hinaus noch auf eine Branchstrategie geeinigt (siehe 4.2 Branching Vorgehen):
Grundsätzlich wurde für jedes in der Entwicklung befindende Feature, ein Feature-Branch angelegt. Nach Fertigstellung und Code Review durch die Gruppe, wurde dieser Branch dann über einen Pull Request in den in unsern Main-Branch integriert. Darüber hinaus habe ich im aktuellen Sprin eine Github Action gebaut. Die Github Action ist so gebaut dass diese bei jedem Push oder Pull Request ausgelöst wird. Sie ist so gebaut, dass der Projekt mit Maven gebaut wird und alle Tests ausgeführt werden. Github Action waren für uns dank des "Github Student Developer Packs" kosteneffizient nutzbar für uns. 
Den Sprint haben wir abgeschlossen mit einem Sprintreview sowie einer Retrospektive, in der wir den Sprint nochmal bewertet haben.
\section{Sprint 2 21.03.2025 bis 09.05.2025}
Der Sprint wurde am 21.03.2025 in Präsenz durch unser Planning gestartet. Eine der Hauptaufgaben die wir uns für den kommenden Spring vorgenommen hatten, war die Entscheidung für eine KI-Technologie die zum Einsatz kommen sollte. Christian, Daniel und ich haben den Freitag und den Samstag nach den Vorlesungen genutzt, um im Rahmen einer Mob-Programming-Session die Möglichkeiten für die Implementierungen einer lokalen KI zu evaluieren. Wir haben unsern Schwerpunkt in das  Fine-Tuning vortrainierter Modelle gelegt, da wir den Aufbau einer neuen generativen KI nach kurzer Diskussion für deutlich zu aufwändig hielten. Mit Pythonskripten und ausgewählten Testdaten haben wir versucht eine auf unsern lokalen Endgeräten lauffähige generative KI zu erzeugen. Unsere Verfügbare Hardware stellte sich dabei immer wieder als Problem für unser Vorhaben heraus. Die Rechenkapazität unser lokalen Endgeräte war der Grund warum wir für unsere lokalen Versuche Kompromisse in der Modellgröße eingehen mussten. Unsere Versuche erstreckten uns an diesen beiden Tagen über mehrere Varianten von lokalen GPT-2 Modellen und verschiedenen lokal lauffähigen Llama-Varianten. Christian und Daniel nahmen sich für den weiteren Sprint dann vor noch tiefer in diesen Prozess einzusteigen und ich übernahm die Aufgabe Testdaten zu beschaffen und aufzubereiten. Hierfür habe ich mit über Python verschiedene E-Mail Datenbanken abgefragt und die Daten anschließend in ein JSON Format strukturiert. Um die Anzahl der Testdaten zu erweitern, habe ich mir von ChatGPT verschiedene Phising-Mails genieren lassen. Durch die Kombination der von ChatGPT generierten Daten und der abgefragten realen Daten konnte ich die Datenbasis beträchtlich erhöhen.
In unserm wöchentlichen Meeting stellte sich im Review der Ansatz einer eignen KI unter den gegebenen Rahmenbedienungen als nicht umsetzbar heraus. Die begrenzte Rechenleistung und unser eher kleiner finanzielle Rahmen machten dieses Vorhaben zu einer nicht lösbaren Aufgabe für unsere Gruppe. Wir einigten auf einen neuen Ansatz zu verfolgen, nämlich den Aufruf eines KI-Service über eine REST-API. Unsere Wahl viel auf den europäischen Anbieter Mistral AI(vgl. 5.1). In einer gemeinsamen Mob-Programming-Session implementierten wir den API Aufruf. In anschließenden Debug-Sessions verfeinerten wir den System-Prompt, sodass die Qualität der E-Mails unsern Anspruch entsprach. Ein weiterer wesentlicher Punkt war das wir die erzeugten Email in Form eines strukturierten HTML Formats haben wollten. Wir haben das HTML Format bewusst gewählt, um die Authentizität und Qualität unser Emails zu erhöhen, die über einfach Textnachrichten hinausgehen. Wir mussten hier noch einige Anpassungen machen, damit das gewünschte Format verlässlich erzeugt wird.
Im weiteren Verlauf des Sprints baute ich für die Phishing-Mails die Kernlogik in dem lokalen Backend-Service . Ich habe Endpunkte fürs Frontend implementiert, die das verwalten und anlegen von von Phishing-Kampagnen erlaubt, sowie das anlegen und verwalten von Email-Empfängerlisten ermöglichen. Hierfür habe ich entsprechende MongoDB-Collections angelegt. Immer wieder wurde im Rahmen dieser Implementierungen im Pair oder Mob gearbeitet. Im Rahmen dieser Implementierung identifizierte ich Schwächen und Unklarheiten im eigentlichen Prozess, was ich auch im abschließenden Review entsprechend anmerkte. Um den Phising-Prozess Robust zu bekommen habe ich vor dem Abschluss des Sprints noch das Fehlerhandling implementiert. Ich nutzte hierfür das Spring Pattern "Controller Advice". Darüber hinaus habe ich abschließend den Code durch gezielte Refactorings sauberer und lesbarer gestaltet um eine Wartung und Weiterentwicklung zu gewährleisten. Erwähnt sei noch, dass die meisten der eingebrachten Änderungen im Rahmen eines testgetriebenen Vorgehens versucht worden zu entwickeln. 
Der Sprint wurde mit einem ausgedehnten Review in der wir die Funktionalität zur Erzeugung der HTML-E-Mails erfolgreich präsentierten abgeschlossen. Um die Implementierungsqualität und den Wissensaustausch zu gewährleisten gingen wir anschließend noch in den technischen Diskurs bei einem Codereview. In unser Retrospektive reflektierten wir den Sprint und unsere Zusammenarbeit bezogen auf das ganze Team durch unsern Projektfortschritt war die Stimmung im Team grundsätzlich sehr positiv.
\section{Sprint 3 09.05.2025 bis 27.06.2025}
Wie ich bereits im dem Eintrag zum letzten Sprint beschrieben habe, fiel mir im Rahmen der Implementierung  der Features für das Phishing-Modul auf, dass der Prozess bezogen auf das Gesamtprodukt noch unsauber oder teilweise unklar ist. Im Rahmen unseres Plannings adressierte ich den Bedarf nochmal über die Prozesse des gesamten Projektes zu reden. Im Fokus stand die Funktionalität der einzelnen Module bezogen auf das Gesamtprodukt. m Rahmen der Durchführung des Workshops  stellte jede Workstreamgruppe nochmal ihren Prozess im Kontext des Gesamtproduktes vor. Bei Unklarheiten diskutierten wir gemeinsam im Kollektiv wie der Prozess aussehen sollte. Ich empfand den Termin aus überaus wert schöpfend für das gesamte Projekt. Auf dieser Basis konnten wir unsere Userstories verfeinern, erweitern und teilweise auch streichen. Für das Phishing-Modul wurden essentielle  Prozessfragen wie, dass der Anwender eine Empfängerliste erst anlegen muss um eine Mailkampagne erstellen zu können oder das eine Email die generiert wird und an verschiedene Empfänger versendet wird, als Kampagne in dem System gehalten und verwaltet wird. In unser Workstreamgruppe stand darüber hinaus noch das das aufsetzen des API-Contracts für das Phising-Modul mit Swagger (OpenAPI) auf dem Plan. Swagger Open Api wird verwendet um Schnittstellen zu beschreiben, die ein Service anbietet. Es ist vor allen Dingen dazu Gedacht, dass sich potenzielle Verwender der Schnittstelle transparent über die Endpunkte und die angebotenen Funktionalitäten informieren können. Wir entschieden uns bewusst dafür diese Spezifikation im Rahmen eines Design-First‘-Ansatz händisch zu erstellen, anstatt sie aus dem Projekt generieren zu lassen. Dies war äußerst zielführend, da wir uns nochmal bewusst Gedanken über die von uns Angebote Schnittstelle machen mussten. 
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.9\textwidth]{figures/swagger.png} 
    \caption{Händisch erstellte Swagger Datei im Sprint 3}
    \label{fig:architektur}
\end{figure}
Im laufe dieses Sprints fanden immer wieder punktuelle Code Reviews statt. Ein Beispiel hierfür war die Vorstellung der Sicherheitsarchitektur im lokalen Spring Backend durch einen Teamkollegen (Tom). Dieser Wissenstransfer erwies sich als äußerst Wertvoll für meine eigene Arbeit, da ich auf Basis der vorgestellten Methoden später ähnliche Security-Filter in das das Phishing-Modul Backend implementieren konnte. Wir haben uns intensiv mit der Nutzerführung beim erstellen einer Phishing-Kampagne auseinandergesetzt. Als optimalen Lösungsansatz identifizierten wir einen Stepper beziehungsweise Wizard, die die Umfangreiche Erstellung in logische aufeinanderfolgende Schritte unterteilt. In einer Mob-Programming-Session implementierten wir eine ersten Proof of Concept dieses Wizards. In einen späteren iterativen Prozess überarbeite Sebastian den Wizard in dem er ihn hinsichtlich des UX-Design und der visuellen Gestaltung optimierte.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/wizard.png} 
    \caption{Der finale Wizard}
    \label{fig:architektur}
\end{figure}
Ein weiterer technischer Schwerpunkt dieses Sprints lag in dem Aufbau eines Spring Cloud Gateway. Ich entwickelte das Gateway wurde als zentrale Komponente zwischen den Lokalen Backend und unseren Modulen. Ziel war es eine saubere Trennung zwischen den lokalen Komponenten beim Anwender und unsern Cloud Komponenten zu schaffen sowie eine einheitliche Kommunikation zu gewährleisten.
\begin{itemize}
  \item \textbf{Zentrales Routing}: Es ist als Proxy konzipiert und leitet die eingehen Anfragen an die entsprechenden Module weiter.
  \item \textbf{Sicherheit}: Das Gateway führt eine initiale Rechteprüfung durch, hierbei prüft es dem vom lokalen Backend übergeben Nutzungsschlüssel auf Gültigkeit. Bei Erfolgreicher Prüfung wird vom Gateway ein neues JSON Web Token (JWT) generiert, welches für die interne Kommunikation mit den Modulen verwendet wird.
\end{itemize}
Durch dieses Design sind die einzelnen Module von der Kommunikation von außen entkoppelt. 
Zur Qualitätssicherung dieser Implementierung führte ich eine Reihe von End to End Test durch. Unter Verwendung des API-CLients Bruno teste ich den gesamten Datenfluss vom Lokalen Backend zum Gateway und anschließend zum Phishing-Modul. Um realistische Bedingungen zu testen, entwickelte ich ein Python-Skript für Lasttests, welches 10 gleichzeitige Anfragen an unsere Backends ausführen kann. Dabei identifizierte ich das Problem, dass unser Mistral Agent bei zu vielen zeitgleichen Anfragen mit dem Status Code 429 (Too Many Requests) abbrach. Nach eingehender Recherche wurde festgestellt, dass unser kostenloser Studententarif lediglich zwei gleichzeitige Aufrufe erlaubt. Wir entschieden uns Teamintern in der Entwicklungsphase diesen Tarif zunächst nicht zu erweitern. Um auf die identifizierten Msitral-Api Beschränkungen professionell zu reagieren habe ich zwei Änderungen an dem Aufruf der Mistral-Api eingebracht:
\begin{itemize}
  \item \textbf{Explizites Error-Handling mit Retry-Logik}: Das Backend wurde so erweitert, dass es auf den Fehlercode 429 gezielt reagiert. Bei Auftreten des Fehlercodes wird automatisch ein neuer Versuch eingeleitet (bis zu Maximal drei Versuchen). 
  \item \textbf{Concurrency Control mittels Semaphoren}: Zusätzlich habe ich einen Semaphore implementiert, dieser limitiert die Anzahl der gleichzeitig ausgehenden Anfragen an die Mistal-API auf maximal zwei Threads. Überzählige Anfragen werden in eine Warteschlange gesetzt.
\end{itemize}
Zum Abschluss des Sprints gab uns Tom nochmal Einblicke in die Umsetzung des Deployments mittels Plesk. Ich empfand diesen Austausch als wirklich interessant und wert schöpfend, da ich bisher deploys immer dierkt über GitHub oder Jenkins gemacht hatte. Ich unterstütze den Prozess indem ich entsprechenden Weebhooks in unsern GitHub-Repositories konfigurierte. Im abschließenden Review wurden  alle Anpassungen präsentiert und diskutiert. Die Abschließende Retrospektive unterstrich die positive Dynamik in der Projektgruppe. Das Team funktioniert gut, die Kommunikation ist effizient und alle Aufgaben wurden zielgerichtet erledigt.
\section{Sprint 4 27.06.2025.03.2025 bis 25.07.2025}
Der Sprint startete mit unsern Planning am 27.06.2025, im Fokus Stand die vollständige Implementierung des Datenbankmodells in das Lokale Backend. Darüber hinaus wollten wir zum verwalten der Datenbankeinträge Schnittellen bereitstellen (CRUD Operationen). Ein weiterer Meilenstein in diesem Sprint war für uns der echte Mailversand und die draus resultierende Erstellung und Persistierung der Kampagne. 
Eine Kampagne stellt eine eingestände Entität in unserer Datenbank dar. Eine Kampagne fungiert als eine Oberklasse, die die eigentliche Mail, alle Konfigurationsparameter und dynamische Werte zur Kampagne wie Klickrate oder den Status hält.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.8\textwidth]{figures/DbModell.png} 
    \caption{Das fertige Datenmodell im Lokalen Backend}
    \label{fig:architektur}
\end{figure}
Für mich begann der Sprint mit Performance Optimierung bei der Mailerstellung. Im Rahmen von iterativen Tests ermittelte ich, dass die realtiv hohen Durchlaufzeiten beim erstellen von Mails auf die Verarbeitungszeit der generativen KI (Mistral AI) zurückzuführen ist. Daraus ergab sich für mich eine zentrale architektonische Problemstellung, denn ein Srpingbackend nutzt in der Regel Thread-per-Request-Modell (Tomcat), dass heißt für jedem Aufruf wird ein Thread zugewiesen. Das Problem ist diese Threads gelten als teuer, da sie direkt Systemressourcen gebunden sind. Bei steigender Last besteht hier die Gefahr, dass es zu einem Thread Starvation kommen kann. Hierbei wäre der Service nicht mehr erreichbar, weil alle Threads zurzeit auf eine KI Antwort warten ohne dabei (und das ist wichtig) tatsächlich die ihnen zugewiesene Rechenleistung zu nutzen. Wir könnten in diesem Szenario dann nur durch mehr Severinstanzen oder durch einen größeren Threadpool pro Instanz skalieren, obwohl das ja eigentlich gar nicht nötig wäre, da unsere Kapazitäten gar nicht genutzt werden sondern nur durch warten blockiert werden.
Ich erarbeite drei Ansätze um mit dieser Problemstellung umzugehen:
\begin{itemize}
  \item \textbf{Akzeptanz und Fehlertoleranz}: Bei diesem Ansatz wäre würde das bestehende Modell beibehalten und das Fehlerhandling optimiert.
  \begin{itemize}
  \item \textbf{Vorteil}: Kein Implementierungsaufwand und keine erhöhte Codekomplexität
  \item \textbf{Nachteil}: Bei Hoher Last Gefahr, dass Service nicht mehr Erreichbar ist beziehungsweise nur teuer skaliert werden kann.
  \end{itemize}
  \item \textbf{Reaktives Programmiermodell (Spring WebFlux)}: Bei diesem Ansatz würden wir von einem imperativen Modell auf ein reaktives umstellen. Bei einem reaktiven Programmiermodell sind die Threads nicht fest an den Anfragen gebunden sondern reagieren auf tatsächliche Ereignisse.
    \begin{itemize}
  \item \textbf{Vorteil}: extrem gute Ressourceneffizienz selbst bei vielen Anfragen
  \item \textbf{Nachteil}: Die Codebasis müsste vollständig umgeschrieben werden, da hier keine blockierenden Codeteile mir vorhanden sein dürfen. Dies würde auch alle extern eingebundenen Bibiotheken betreffen. Zudem würde sie die Komplexität massiv erhöhen, was das Debugging und die Einarbeitung des Team behindern würde.
  \end{itemize}
    \item \textbf{Virtual Threads}: Seit Java 21  gibt es die Möglichkeit Threads zur zu virtualisieren. Hierbei würden wir die blockierenden Aufrufe akzeptieren, aber die Threads sehr günstig machen, da wir diese von den echten Systemkapazitäten entkoppeln
      \begin{itemize}
  \item \textbf{Vorteil}: aus wenigen physischen Threads können Millionen leichtgewichtige virtuelle Threads entstehen. Codebasis bleibt weitesgehend gleich.
  \item \textbf{Nachteil}: Virtuelle Threads erhöhen nicht die Rechenleistung. Sie bieten sicher daher nicht für rechenintensive Anwendungen an.
  \end{itemize}
\end{itemize}
Ich habe diese Punkte unserm Workstream Team vorgestellt und gemeinsam haben wir uns auf den Einsatz von Virtual Threads geeinigt, da sie unser Problem lösen ohne die Architektur grundlegend zu verändern. 
Im laufe dieses Sprint implementiere ich weitestgehend in Pair- und Mob-Programming-Sessions das Datenbankmodell in das lokale Backend. Das heißt wir haben die entsprechenden Klassen in Java angelegt und die entsprechenden Services für den Zugriff auf die MongoDB gebaut. Darüber hinaus haben wir einen Controller implementiert der die vereinbarten Schnittstellen zur Verfügung stellt. Wir haben im nächsten Schritt diese Schnittstellen auch aus dem Frontend angebunden. Es war nun erstmalig möglich aus dem Frontend Daten im Backend zu verwalten.
In weiteren Pair- und Mob-Programming-Sessions haben wir die Versandfunktionalität umgesetzt. Hierbei hinterlegten für die Testphase unser eigener Mailserver angebunden. In Produktivbetrieb ist es so Gedacht, dass der Anwender bei der Installation seinen Mailserver als Umgebungsvariable mitgibt. Zum versenden der HTML Mails setzen wir auf Springmail in Kombination mit MimeMessage. Ummittelbar vor dem Versand erfolgt eine dynamische Personalisierung mit Anrede und Titel. Um Fehlsendungen und Missbrauch vorzubeugen, ist es während unsern Proof of Concept Phase nur möglich echte Mails an Empfänger einer festgelegten Testliste herauszuschicken.  Alle andern Sendevorgänge werden lediglich im System geloggt. Nach dem erfolgreichen Versenden der Mails wird eine neue Kampagnen-Entität in der Datenbank gespeichert. Diese speichert unter andrem die Referenzen (ID) der Empfänger um später das Interaktionsverhalten nachverfolgen zu können. 
Nun war es uns möglich auch erstmalig den End-to-End-Workflow zu durchlaufen von anlegen der Empfängerlisten bis zum finalen Versand der Mails.
Der Sprint endete mit unsern Review und Retrospektive am 25.07.2025. Im Rahmen der Review präsentierten wir unsere Fortschritte. Ich bin hier zum Beispiel nochmal explizit auf die Virtual Threads eingegangen, die eingebaut wurden. Die Retrospektive zeigte, dass unser Projektteam weiterhin hoch motiviert ist und äußert gut zusammen arbeitet.
\section{Sprint 5 25.07.2025 bis 19.09.2025}
Dieser Sprint begann mit unserem Planning Vorort in der OHM Professional School am 25.07.2025. Aufgrund von geplanter Urlaubzeiten in unserm Projektteam haben wir das Volumen der geplanten Features bewusst reduziert um auf diese Situation zu reagieren. Als Workstreamgrupe setzen wir in diesen Sprint darauf, die bestehenden Platzhalter in den generierten E-Mails durch trachkbare Links zu ersetzen. Darüber hinaus nahmen wir uns noch vor, den Wizard um einen initialen Step zu erweitern, in dem der Anwender die Kampagnenrahmendaten erfassen muss.
Die Implementierung der trackbaren Links fand wie viele der Kernfeatures des Phising-Modul im Rahmen einer Mob-Session statt. Wichtig war es hier, dass für jeden Empfänger ein Link erstellt wird, um die Klicks personenbezogen nachvollziehen zu können. Technisch haben wir hierfür die Codestelle gewählt in der wir schon die Anrede und den Titel individualisieren. Der Link der zur Laufzeit erstellt wird zeigt auf einen GET Endpunkt in unsern Backend, wobei eine eindeutige GUID  als Pfadparameter übergeben wird. Wenn der Endpunkt aufgerufen wird, wird ein entsprechender Eintrag mit der GUID in der Kampagne hinterlegt. Dies bot uns die Möglichkeit diese Daten dann später für Auswertungszwecke dem Frontend zur Verfügung zu stellen. 
Ergänzend zur Mailverfolgung habe ich Möglichkeiten untersucht, um das öffnen der Mails im Mailprogramm nachverfolgen zu können. Technisch erwies sich das als Herausforderung, daher entwickelte ich einen Proof of Concept. Ich bette in jede verschickte HTML-Email ein sogenanntes "Trackingpixel" (1x1-Bild) mit ein. Dieses Bild soll dann über einen Restaufruf ans Backend nachgeladen werden. Auch hier dient die individuelle GUID als Parameter im Link um den Aufruf zuzuordnen zu können. Sobald ein Mailprogramm die Mail öffnet wird der Aufruf verschickt. Ein großer Nachteil an diesem Ansatz ist, dass viele moderne Email-Clients standardmäßig das nachladen von Bildern blockieren. Dies schränkt die Zuverlässigkeit dieses Ansatzes ein. Gemeinsam in der Projektgruppe haben wir dann entschieden das Feature beizubehalten, um tendenziell die Möglichkeit zu bieten die Öffnungsraten nachverfolgen zu können. Auf Basis dieser Entscheidung mergde ich nach einem Umfangreichen Codereview meinen Entwicklungsbranch mit diesem Feature in unseren Hauptbranch rein. Im Weiteren Verlauf dieses Sprints, habe ich verschiedene Probleme beim Aufruf und Löschen von Empfängerlisten behoben. Ein kritischer Fehler war, dass beim Löschen einer Empfängerliste alle in Ihre vorkommenden Empfänger gelöscht wurden, ohne das Geprüft wurde, ob die Empfänger noch in andern Empfängerlisten verwendet wurden. Um diesen Fehler zu beheben, baute ich vor dem Endgültigen Löschen der Empfänger eine Prüfung ein die alle aktiven Empfängerlisten nach den zu löschenden Empfängern prüft. Im Fall das ein Empfänger bei der Prüfung in einer andern aktiven Empfängerliste vorkommt, wird dieser Empfänger nicht gelöscht. Darüber hinaus nahm ich noch weitere Anpassungen an dem Hinzufügen und Löschen von Empfängerlisten im Frontend vor. Die Anpassungen fanden primär in der Typeskript Logik und der Kommunikation zwischen Backend und Frontend statt. Zum Beispiel habe ich die entsprechenden Endpunkte des Backends im Frontend angebunden und ausgewertet. Vor Abschluss dieses Sprintes entwickelten wir in einer weiteren Mob-Sessions den initialen Step beim anlegen einer Phishing Kampagne. Der Hauptteil der Arbeit lag im Frontend und in der Übergabe der neuen Daten ins Backend. Im Backendes wurden lediglich die Datenobjekte erweitert. 
Der Sprint endete mit der Retrospektive und dem Review. Beim Review wurden wie immer die Ergebnisse des Sprints vorgestellt und kritisch hinterfragt. Wir stellten hier den Workflow rund um die Empfängerlisten vor. In der Retrospektive zeigte, dass das Projektteam grundsätzlich zufrieden ist, aber Verbesserungspotenziale in der Kommunikation sieht. Die eingeschränkte Kommunikation in diesem Sprint, war aber auch auf die Urlaubssituation zurückzuführen. Dennoch nahmen wir uns vor im nächsten Sprint auf eine klarere Kommunikation zu achten. 
\section{Sprint 6 19.09.2025 bis 24.10.2025}
Bei unserem Planning Vorort am 19.09.2025 lag unser Fokus primär drauf den bestehenden Code zu refactoren und auf der Behebung von offenen Bugs. Aufgrund des verhältnismäßig kurzen Sprint nahm ich mir, um noch genug Zeit für die Klausurvorbereitungen zuhaben, vor relativ früh im Sprint meinen Beitrag zu leisten. Das Refactoring fand im Rahmen von Mob-Session statt. Dies war uns besonders wichtig, um sicherzustellen das unsere Codebasis von jedem Workstreammitglied eigenständig gewartet werden kann. Beim Refactoring konzentrierten wir uns drauf den Code lesbarer und sauberer zu gestalten. Wir orientierten uns dabei an Industriestandards. Als Orientierung dienten uns hierbei unter anderem die objektorientierten Patterns der "Gang of Four" (vgl. \cite{gamma1994design}). Uns war es wichtig die Komplexität der einzeln Methoden soweit zu reduzieren, dass sie jeder Entwickler ohne eine umfassende Einarbeitung wartbar sind. Die Anzahl der einzelnen If Cases und die Methoden sowie die Klassenlänge waren dafür wichtige Indizien. Weiterhin setzen wir auf eine klare und einheitliche Namensgebung unserer Klassen, Methoden und Variablen. Aus den Namen soll immer der eigentliche Zweck des Objekts ersichtlich sein.JSON-Parameter werden im "Snake-Case" notiert und normale Variablen, Methoden und Klassen unter Berücksichtigung der Java-Standards im "Camel-Case". Im weiteren Verlauf des Sprints lag der Fokus auf der Behebung von Bugs. Ein kritischer Fehler war, das Fehlen eines Rollbacks, wenn das Versenden der E-Mails auf einen Fehler gelaufen ist. In diesem Szenario wurde trotzdem das Kampagnen Objekt in der Datenbank angelegt, obwohl keine Mails versandt wurden. Das erstellen der Kampagnen Objekte findet im technischen Ablauf vor dem versenden der Mails statt, da wir beim versenden der Mails die Kampagnen - Id mit in den Link schreiben um die Klicks zuordnen zu können. Den Bug konnte ich durch gezieltes Fehlerhandling beheben, schlägt der Versand der E-Mails fehl wird gezielt ein Rollback ausgeführt. Hierfür setze ich auf eine kompakte Try und Catch Logik. 
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/testpr.jpg} 
    \caption{Testpyramide Fokus Backendservices}
    \label{fig:architektur}
\end{figure}
Zum Abschluss des Sprints erarbeite ich ein Testkonzept für unsere Backends. Mein Ziel war es für die bestehenden Backends eine ganzheitliche Teststrategie zu etablieren.
\begin{itemize}
  \item \textbf{Unittests}: Unittests bilden das Fundament unsere Teststrategie, sie wurden fortlaufend während der Entwicklung bevorzugt Testdriven implementiert. Sie testen alle  Methoden vollständig isoliert.
  \item \textbf{Integrationstest}: Integrationstests testen den Workflow innerhalb eines Services. Hier wird die Zusammenarbeit zwischen verschiedenen Komponenten des Services getestet.
    \item \textbf{Contract Tests}: Diese Tests können als Vertragstests zwischen zwei Schnittstellenpartnern angesehen werden. Sie sollen in erster Linie "Breaking Changes" verhindern. Dies stellt sicher, dass Änderungen an einem Service nicht die Lauffähigkeit abhängiger Partner-Services beeinträchtigen.
    \item \textbf{End to End Tests}: Stellen einen automatisierten Durchlauf des kompletten Benutzerflusses dar. Sie können auch als eine Art automatisierter Abnahmetest angesehen werden. Sie stellen sicher, dass die Geschäftslogik aus Anwendersicht funktioniert. 
\end{itemize}
Der Sprint endete am 24.10.2025 mit unser Review und unserer Retrospektive Vorort in Nürnberg. Im Rahmen der Review stellte ich dem gesamten Projektteam, dass von mir erstellte Testkonzept vor. Wir einigten uns drauf, im nächsten Sprint die zusätzlichen Tests zu implementieren. 
In der Retrospektive zeigte sich das Team immer noch als äußert motiviert und produktiv. 
\section{Sprint 7 24.10.2025 bis 05.12.2025}
Unser Sprint startete mit dem Planning am 24.10.2025 Vorort in Nürnberg. Fokus lag in diesem Sprint auf dem Abschluss der Feature Entwicklung. Unser Ziel war es Voraussetzungen zu schaffen, die es uns erlauben uns im darauffolgenden Sprint auf den Bugabbau und die Verbreitung der Präsentationen zu konzentrieren. 
Relativ früh im Sprint traf sich unsere Workstreamgruppe persönlich Vorort in Nürnberg um gemeinsam die finalen Features im Phishing-Modul zu implementieren. Im Rahmen eines intensiven Workshop-Samstags (10 Uhr bis 20 Uhr) implementieren wir die noch offenen Features für das Modul. Diese Präsenztreffen habe ich stets als besonders produktiv und konstitutiv wahrgenommen. Ein Highlight dieses Samstag war unter andrem die Implementierung einer Zugstimmungsseite, die der erstmaligen Nutzung der Zustimmungsseite vorgeschaltet ist. Die Steuerung erfolgt über ein Flag in der Datenbank:
\begin{itemize}

    \item \textbf{Backend-Logik}: Über einen Endpunkt wird geprüft, ob der Nutzer den Nutzungsbedingungen schon zugestimmt hat. Hierbei wird zu Bestimmung des Nutzers der Auth-Header aufgelöst, um den Status aus der Datenbank abzufragen.
    \item \textbf{Frontend-Logik}: Basierend auf diesen Informationen wird der Anwender entweder direkt zu dem Modul weitergeleitet oder zu Bestätigung der Nutzungbedinugnen aufgefordert. Sobald der Nutzer den Bedienungen zugestimmt hat, wird die Flag in der Datenbank gesetzt.
\end{itemize}
Ich nahm mir für diesen Sprint weiterhin das ambitionierte Ziel vor die Teststrategie im Backend weitestgehend zu implementieren. Neben den bereits während der Entwicklung bevorzugt testgetriebenen implementierten Unstetestes nahm ich mir vor Integrationstest, Contract Test und End To End Tests zu entwickeln. Wichtig bei den Integrationstest war, dass sie in den Mirkoservices selbst nichts mocken, sondern die tatsächlichen Implementierungen aufgerufen werden. Die Integrationstests wurden technisch als Unitetessts mit größeren Scope gebaut. Um ein realistisches Verhalten der Datenbank zu erhalten ohne diese zu mocken, wird die Bibliothek Testcontainers eingesetzt. Diese ermöglicht es während der Testlaufzeit isolierte Dockercontainer hochzufahren und mit bestimmter Software zu bestücken. Nach Abschluss des Tests werden diese Container wieder verworfen. Damit die Tests lokal ausführbar bleiben braucht es lokal einen Container mit der Datenbank. Dafür setzte ich auf Podman, der die Container bereitstellen kann. In der CI/CD Pipline (GitHub Actions) werden diese Tests ebenfalls mithilfe von Containern ausgeführt (vgl. \cite{podman2025, testcontainers2025}). Für die Contracttests setzte ich auf PACT. Mit PACT hatte ich bereits im Rahmen meines Berufs positive Erfahrungen gemacht. PACT wird eingesetzt um Interaktionen zwischen Schnittellenpartnern verbindlich über sogenannte Pacts zu definieren. Dies hilft dabei nicht beabsichtige Breakingchanges zu verhindern (vgl. \cite{pact2025docs}). 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/pact.png} 
    \caption[Pact Ablauf]{Pact Ablauf (Quelle: \cite{pact_docs})}
    \label{fig:architektur}
\end{figure}
Der grundsätzliche Gedanke ist, dass Consumer und Provider einigen sich auf einen PACT (Contract) und testen dagegen, sobald einer der beiden eine Änderung einbringt, die den Contract verletzt laufen die Tests auf einen Fehler. Bei unsern Pacttest konzentrierte ich mich primär auf die Verbindungen von dem Lokal Backends zu unsern Modulen. Das liegt daran, dass wir nach der Auslieferungen unser OnPremise Software nicht mehr so leichtgewichtig Änderungen einbringen können wie wir es in einer Cloud Umgebung machen können. Fehler, die die Contracts zwischen den Backends hier verletzen, können sehr teuer werden im produktiven Betrieb. Aufgrund unser Limitieren finanziellen Ressourcen erstelle ich den PACT durch Consumerpact Tests im Lokalen Backend und speicherten anschließend den PACT in das jeweilige Modul Backend. Es gibt PACT Brooker wie PactFlow die einem diese Arbeit abnehmen, in dem sie die Pacts zentral verwalten, allerdings sind diese Lösungen relativ kostspielig und ich habe bewusst drauf verzichtet diese in unsere Services einzubinden. 
Mit den Unittests, Integrationstest sowie den Pacttests sind die rein Backendsseitigen Tests der Teststrategie von mir in diesem Sprint implementiert worden. Die End to End Test nahm ich mir vor zwischen den Jahren in das Frontend zu implementieren. In den Backends kommen wir auf eine Codecoverage von ungefähr 90 Prozent.
Der Sprint endete mit unser Review und unser Retrospektive am 05.12.2.025. In der Review stellte ich die implementierten Tests vor. Wir konnten die meisten der offen Features erledigen, sodass wir in den finalen Sprint uns nur noch mit dem Bugabbau beschäftigen konnten. 
\section{Sprint 8 05.12.2025 bis 26.02.2026}
Der finale Sprint begann am 5.12.2025 wieder Vorort in Nürnberg mit unserm Planning. Im Fokus dieses Sprintes stand der Bugabbau. Wir nahmen uns darüber hinaus vor keine produktiven Erweiterungen in das System mehr einzubringen und ab Mitte Januar keine Changes mehr im Code einzubringen um sicherzustellen, dass wir bei den Präsentationen im Februar eine funktionsfähige Software vorzeigen können. Ein besonders Event in diesem Sprint war, dass unser Auftrageber Dr. Dirk Kötting persönlich Vorort war. Wir nutzen seinen Anwesenheit für einen Usabillty Test unserer Anwendung, den wir mit Ihm ausführten. Unser Produkt Owner Christian Langer hatte dahingehend die nötigen Vorbreitungen getroffen. Meine Aufgabe hierbei war es, Dr. Dirk Kötting zu beobachten und Notizen zu machen, inwieweit er intuitiv die Anwendung bediente. Die hieraus resultierenden Erkenntnisse erfassten wir als Bugs. In diesem Sprint beschäftigte ich abschließend mit den Einbau von End to End Tests um unsern Modul Workflow komplett zu testen. Es gibt eine Reihe von Frameworks und Tools die einem bei diesen Tests unterstützen. Nach intensiver Recherche entschied ich mich Playwright zu nutzen. Playwright bietet die Möglichkeit moderne Browser automatisiert zu steuern. Es bietet dem Anwender die Möglichkeit seine spezifischen Workflows automatisiert und performant zu testen(vgl. \cite{playwright2025docs}). Die Implementierung erwies sich als äußert intuitiv und einfach. Nach kurzer Eingewöhnungszeit war es mir möglich umfangreiche Playwright Tests zu bauen, die die Prozesse des Anwenders realistisch darstellen. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/playwright beispiel.png} 
    \caption{Ausschnitt aus den Playwright Tests}
    \label{fig:architektur}
\end{figure}