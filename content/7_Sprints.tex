\chapter{Sprints}\label{app:Sprints}
\section{Sprint 0 24.01.2025 bis 21.02.2025}
Nach der Zusage der Verwaltung, dass wir das Projekt in der ursprünglich von uns beantragten Gruppe durchführen dürfen, setzten wir uns zeitnah mit Dr. Kötting in Verbindung. Hinsichtlich des Themas hatten wir noch Bedenken, da Dr. Köttings initiale Projektidee, die er auch in der ersten Informationsveranstaltung des Studiengang vorgestellt hatte, uns allen nicht gefiel. Im ersten Gesprächen stellte sich allerdings heraus, dass Herr Dr. Kötting offen dafür war, das Thema anzupassen, und daher beauftragte er uns mit der Ausarbeitung einer neuen Projektidee. Ihm war es wichtig, dass die ausgearbeitete Projektidee Fragestellungen oder Probleme mit Hilfe von KI lösen kann.
Das Projektteam erarbeitete sich die Projektidee im Rahmen einer strukturierten Kreativitätsphase.
Hier wurde das "1-3-All"-Verfahren genutzt (angelehnt an das "1-2-4-All" Verfahren 
\cite{Desginthinking124}), um eine große Menge an Ideen zu entwickeln. Nach der Sammlung der Ideen  stellte jede Person ihre Ideen der Gruppe (3er-Gruppe oder alle) vor, wo diese dann im Kollektiv diskutiert, verfeinert und gegebenenfalls mit anderen Ideen geclustert wurde. Abschließend hatte jeder Teilnehmer drei Stimmen, um sie auf die erarbeiteten Ideen zu verteilen. Die drei Ideen mit den meisten Stimmen würden nochmal unserm Auftraggeber Dr. Kötting vorgestellt und gemeinsam diskutiert. Wichtige Faktoren waren hier der erwartbare Mehrwert für einen potenziellen Kunden und die technische Umsetzbarkeit.
Letztendlich hat sich die Projektgruppe für das Security-Tool entschieden. Ausschlaggebend waren zum einem die Interessen und Kenntnisse unseres Auftraggebers, von dem dieses Projekt profitiert hat, und zum andern dass dieses Projekt eine Lösungen für echte Probleme von mittelständischen Unternehmen anbietet. 
In einem anschließenden Treffen haben wir uns auf ein Codeverwaltungs- und Projektmanagement-Tool geeinigt.  Für die Codeverwaltung fiel unsere Wahl auf Github als eine der führenden Codeverwaltungsplattformen. Github ist grundsätzlich kostenlos. Ein weiterer Faktor waren die "GitHub-Student-Developer-Packs", mit denen wir einen kostenlosen Zugang zu erweiterten Funktionen und kostenpflichtigen Angeboten erhielten (vgl \cite{github_student_pack}). 
Beim Projektmanagementtool fiel unsere Wahl auf Jira. Auch Jira ist ein auf dem Mark etabliertes Tool im Bereich des Projektmanagements. Wir nutzen Jira zum Verwalten unser Vorhaben in Form von Epics, darunter clusterten wir auch später die jeweiligen Tasks, die wir in dem entsprechenden Sprint bearbeiten wollten. Für die Übersicht haben wir ein Kanban-Board angelegt, wo die entsprechenden Vorhaben mit ihrem aktuellen Status für jedes Gruppenmitglied jederzeit über ihre eigenen Jira Zugänge einsehbar waren. Ein wichtiger Punkt der für Jira gesprochen hatte, war, dass unser Product Owner Christian Langer breites viel Erfahrung im Umgang mit Jira hatte. Er hat das Wissen über den Umgang mit dem Tool ins Projekt getragen.  Im nächsten Schritt habe ich mich um meine lokalen Entwicklungsumgebungen gekümmert. Da ich bereits viel Erfahrung mit den Entwicklungsumgebungen von Jetbrains hatte, wollte ich wieder auf diese setzen. Bei Recherche stieß ich auf das "Jetbrains Student Pack", welches es Studenten erlaubt, alle kostenpflichtigen Entwicklungsumgebungen kostenlos zu nutzen (vgl. \cite{jetbrains_student}). Initial installierte ich PyCharm und Intellij.
Innerhalb unser einzeln Workstreams arbeiteten wir nun die Anforderungen an die jeweiligen Module heraus. Hierbei versuchten wir, aus den groben Epics, auf die wir uns mit Herrn Dr. Kötting committet hatten, einzelne Anforderungen abzuleiten. Christian, Daniel und ich zeichneten für das Phishing-Modul im ersten Schritt ein grobes Ablaufdiagramm, um anschließend draus die einzelnen Anforderungen leichter erarbeiten zu können. Abschließend stellten wir die ausgearbeiteten Anforderungen in der gesamten Projektgruppe vor und besprachen diese. Hier nahmen wir nochmal einige Anpassungen vor, zum Beispiel hinsichtlich der zu auszuwertenden Parameter wie "Schwierigkeitsgrad". Diese Einstellung verwarfen wir nach einigen Diskussionen zunächst.
Nachdem wir alle zufrieden mit den formulierten Anforderungen waren, stellten wir diese auch nochmal unserem Auftraggeber vor, um sicherzugehen, dass diese Anforderungen seinen Vorstellungen entsprechen. Dr. Dirk Kötting brachte hier nochmal sehr gute Einwürfe und wir konnten die initialen Anforderungen nochmal verfeinern. Eine wichtige Anmerkung war der Datenschutzgedanke und der Gedanke der Rechtssicherheit. Daraus leiteten wir zum Beispiel die Anforderung ab, dass der Anwender vor der erstmaligen Nutzung des Moduls eine Nutzungsbedingung akzeptieren muss.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/erster_Wurf_Ablauf.png} 
    \caption{Erster Wurf für den Ablauf des Phishing-Workflows}
    \label{fig:architektur1}
\end{figure}
\section{Sprint 1 21.02.2025 bis 21.03.2025}
In diesem Sprint beschäftigten wir uns mit der grundsätzlichen Architektur innerhalb des Phishing-Moduls. Zunächst einigten wir uns gemeinsam auf die Strategie, eine eigene KI zu schreiben, die unsere Phishingmails generiert. Unter dieser Bedingung planten wir, ein Spring-Backend zu schreiben, welches orchestrierende Aufgaben übernimmt, sowie ein Python-Flask-Backend, welches die KI selbst aufruft.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/EntwurfSprint1.png} 
    \caption{Entwurf der Modul Architektur im Sprint 1}
    \label{fig:architektur}
\end{figure}
Im ersten operativen Schritt legte ich das Grundgerüst des Springbootprojekts an. Zur Erstellung des Projektes verwendete ich den Spring Initializr. Dieses kostenlose Tool ermöglicht eine geführte Erstellung der Projektstruktur. Nach Rücksprache mit Christian und Daniel entschieden wir uns für ein Maven-Projekt in Kotlin. Die Punkte, die für Maven sprachen, sind zum einem seine Leichtgewichtigkeit sowie meine Praxiserfahrung mit dem Buildtool. Dadurch konnte ich Christian und Daniel effizient in das Tool einarbeiten. Für Kotlin entschied ich mich bewusst, denn ich wollte die Sprache im Rahmen des Projektes evaluieren und prüfen, ob sie sich dazu eignet, in meinen Arbeitsprojekten eingesetzt zu werden. Kotlin ist eine deutlich modernere Sprache als Java und bietet einige Vorteile, von denen wir auch im Rahmen unsres Projekts profitiert haben. 
\begin{itemize}
  \item \textbf{Null Saftey}: Variablen müssen explizit als "nullbar" deklariert werden. Das mindert die Gefahr von "NullPointerExceptions" erheblich. Schon während der Entwicklungsphase erwies sich dieses Feature als äußert wertvoll. Zum einen hatten wir nicht viele solcher Exceptions und wenn wir welche hatten, kamen nur nullbare Variablen in Frage.
  \item \textbf{Kompakter Code}:Boiler-Plate Code wird drastisch reduziert. Wir konnten sehr viele Zeilen an Code sparen, allein dadurch, dass Kotlin hier einfach moderner arbeitet  als Java. Beispiele hierfür sind unter anderem das Arbeiten auf Listen, was in Kotlin deutlich eleganter gelöst ist im Vergleich zu Java. 
\end{itemize}
Wir einigten uns darüber hinaus noch auf eine Branchstrategie (siehe 4.2 Branching Vorgehen):
Grundsätzlich wurde für jedes in der Entwicklung befindende Feature, ein Feature-Branch angelegt. Nach Fertigstellung und Code-Review durch die Gruppe wurde dieser Branch dann über einen Pull-Request in unsern Main-Branch integriert. Weiterhin implementierte ich in diesem Sprint eine Github-Action für unsere Backends, welche das Projekt mit Maven baut und testet.  . Die Github-Action ist so gebaut, dass diese bei jedem Push- oder Pull-Request in unseren Main-Branch ausgelöst wird. Github-Actions waren für uns dank des "Github Student Developer Packs" kosteneffizient nutzbar. 
Den Sprint schlossen wir mit einem Sprintreview sowie einer Retrospektive, in der wir den Sprint nochmal bewerteten, ab.
\section{Sprint 2 21.03.2025 bis 09.05.2025}
Der Sprint wurde am 21.03.2025 in Präsenz durch unser Planning gestartet. Eine der Hauptaufgaben, die wir uns für den kommenden Sprint vorgenommen hatten, war die Entscheidung für eine KI-Technologie die zum Einsatz kommen sollte. Christian, Daniel und ich nutzten den Freitag und den Samstag nach den Vorlesungen, um im Rahmen von Mob-Programming-Sessions die Möglichkeiten für die Implementierungen einer lokalen KI zu evaluieren. Wir legten unsern Schwerpunkt auf das  Fine-Tuning vortrainierter Modelle, da wir den Aufbau einer neuen generativen KI nach kurzer Diskussion für deutlich zu aufwändig hielten. Mit Pythonskripten und ausgewählten Testdaten versuchten wir, eine auf unsern lokalen Endgeräten lauffähige generative KI zu erzeugen. Unsere verfügbare Hardware stellte sich dabei immer wieder als Problem für unser Vorhaben heraus. Die Rechenkapazität unser lokalen Endgeräte war der Grund, warum wir für unsere lokalen Versuche Kompromisse in der Modellgröße eingehen mussten. Unsere Versuche erstreckten uns an diesen beiden Tagen über mehrere Varianten von lokalen GPT-2 Modellen und verschiedenen lokal lauffähigen Llama-Varianten. Christian und Daniel nahmen sich für den weiteren Sprint dann vor, noch tiefer in diesen Prozess einzusteigen, und ich übernahm die Aufgabe, Testdaten zu beschaffen und aufzubereiten. Hierfür fragte ich mit Python verschiedene E-Mail Datenbanken ab und strukturierte die Daten anschließend in ein JSON-Format. Um die Anzahl der Testdaten zu erweitern, ließ ich mir von ChatGPT verschiedene Phising-Mails genieren. Durch die Kombination der von ChatGPT generierten Daten und der abgefragten realen Daten konnte ich die Datenbasis beträchtlich erhöhen. Auch für die Kombination der Daten verwendete ich ein Pyhtonskript.
In unserem wöchentlichen Meeting stellte sich im Review der Ansatz einer eignen KI unter den gegebenen Rahmenbedienungen als nicht umsetzbar heraus. Die begrenzte Rechenleistung und unser eher kleiner finanzielle Rahmen machten dieses Vorhaben zu einer nicht lösbaren Aufgabe für unsere Gruppe. Wir einigten uns darauf, einen neuen Ansatz zu verfolgen, nämlich den Aufruf eines KI-Service über eine REST-API. Unsere Wahl fiel auf den europäischen Anbieter Mistral AI(vgl. 5.1). In einer gemeinsamen Mob-Programming-Session implementierten wir den API-Aufruf. In anschließenden Debug-Sessions verfeinerten wir den System-Prompt, sodass die Qualität der E-Mails unsern Anspruch entsprach. Ein weiterer wesentlicher Punkt war, dass wir die erzeugten Emails in Form eines strukturierten HTML-Formats haben wollten. Wir wählten das HTML-Format bewusst, um die Authentizität und Qualität unser Emails zu erhöhen, die über einfache Textnachrichten hinausgehen. Wir mussten hier noch einige Anpassungen machen, damit das gewünschte Format verlässlich erzeugt wird.
Im weiteren Verlauf des Sprints baute ich für die Phishing-Mails die Kernlogik in dem lokalen Backend-Service . Ich habe Endpunkte fürs Frontend implementiert, die das Verwalten und Anlegen von Phishing-Kampagnen erlaubt, sowie das Anlegen und Verwalten von Email-Empfängerlisten ermöglicht. Hierfür habe ich entsprechende MongoDB-Collections angelegt. Immer wieder wurde im Rahmen dieser Implementierungen im Pair oder Mob gearbeitet. Im Rahmen dieser Implementierung identifizierte ich Schwächen und Unklarheiten im eigentlichen Prozess, was ich auch im abschließenden Review entsprechend anmerkte. Um den Phising-Prozess robust zu bekommen, implementierte ich vor dem Abschluss des Sprints noch das Fehlerhandling. Ich nutzte hierfür das Spring-Pattern "Controller Advice". Darüber hinaus gestaltete ich abschließend den Code durch gezielte Refactorings sauberer und lesbarer, um eine Wartung und Weiterentwicklung zu gewährleisten. Erwähnt sei noch, dass die meisten der eingebrachten Änderungen im Rahmen eines testgetriebenen Vorgehens zu entwickeln versucht wurden. 
Der Sprint wurde mit einem ausgedehnten Review, in dem wir die Funktionalität zur Erzeugung der HTML-E-Mails erfolgreich präsentierten, abgeschlossen. Um die Implementierungsqualität und den Wissensaustausch zu gewährleisten, gingen wir anschließend noch in den technischen Diskurs bei einem Codereview. In unser Retrospektive reflektierten wir den Sprint und unsere Zusammenarbeit bezogen auf das ganze Team. Durch unseren Projektfortschritt war die Stimmung im Team grundsätzlich sehr positiv.
\section{Sprint 3 09.05.2025 bis 27.06.2025}
Wie bereits im dem Eintrag zum letzten Sprint beschrieben, fiel mir im Rahmen der Implementierung  der Features für das Phishing-Modul auf, dass der Prozess bezogen auf das Gesamtprodukt noch unsauber oder teilweise unklar ist. Im Rahmen unseres Plannings adressierte ich den Bedarf, erneut über die Prozesse des gesamten Projektes zu reden. Im Fokus stand die Funktionalität der einzelnen Module bezogen auf das Gesamtprodukt. Im Rahmen der Durchführung des Workshops stellte jede Workstreamgruppe nochmal ihren Prozess im Kontext des Gesamtproduktes vor. Bei Unklarheiten diskutierten wir gemeinsam im Kollektiv, wie der Prozess aussehen sollte. Ich empfand den Termin als überaus wertschöpfend für das gesamte Projekt. Auf dieser Basis konnten wir unsere Userstories verfeinern, erweitern und teilweise auch streichen. Für das Phishing-Modul wurden essentielle Prozessfragen wie, dass der Anwender eine Empfängerliste erst anlegen muss, um eine Mailkampagne erstellen zu können, oder, dass eine Email, die generiert und an verschiedene Empfänger versendet wird, als Kampagne in dem System gehalten und verwaltet wird. In unser Workstreamgruppe stand darüber hinaus noch das Aufsetzen des API-Contracts für das Phising-Modul mit Swagger (OpenAPI) auf dem Plan. Swagger Open Api wird verwendet, um Schnittstellen zu beschreiben, die ein Service anbietet. Es ist in erster Linie dazu gedacht, dass sich potenzielle Verwender der Schnittstelle transparent über die Endpunkte und die angebotenen Funktionalitäten informieren können. Wir entschieden uns bewusst dafür, diese Spezifikation im Rahmen eines Design-First-Ansatzes händisch zu erstellen, anstatt sie aus dem Projekt generieren zu lassen. Dies war äußerst zielführend, da wir uns nochmal bewusst Gedanken über die von uns angebotene Schnittstelle machen mussten. 
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.9\textwidth]{figures/swagger.png} 
    \caption{Händisch erstellte Swagger Datei im Sprint 3}
    \label{fig:architektur}
\end{figure}
Im Laufe dieses Sprints fanden immer wieder punktuelle Code-Reviews statt. Ein Beispiel hierfür war die Vorstellung der Sicherheitsarchitektur im lokalen Spring-Backend durch einen Teamkollegen (Tom). Dieser Wissenstransfer erwies sich als äußerst wertvoll für meine eigene Arbeit, da ich auf Basis der vorgestellten Methoden später ähnliche Security-Filter in das Phishing-Modul-Backend implementieren konnte. Wir setzten uns intensiv mit der Nutzerführung beim Erstellen einer Phishing-Kampagne auseinander. Als optimalen Lösungsansatz identifizierten wir einen Stepper beziehungsweise Wizard, die die umfangreiche Erstellung in logische aufeinanderfolgende Schritte unterteilt. In einer Mob-Programming-Session implementierten wir einen ersten Proof of Concept dieses Wizards. In einem späteren iterativen Prozess überarbeite Sebastian den Wizard, indem er ihn hinsichtlich des UX-Design und der visuellen Gestaltung optimierte.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/wizard.png} 
    \caption{Der finale Wizard}
    \label{fig:architektur}
\end{figure}
Ein weiterer technischer Schwerpunkt dieses Sprints lag in dem Aufbau eines Spring-Cloud-Gateways. Ich entwickelte das Gateway, das  als zentrale Komponente zwischen dem lokalen Backend und unseren Modulen konzipiert ist. Ziel war es, eine saubere Trennung zwischen den lokalen Komponenten beim Anwender und unsern Cloud-Komponenten zu schaffen, sowie eine einheitliche Kommunikation zu gewährleisten.
\begin{itemize}
  \item \textbf{Zentrales Routing}: Es ist als Proxy konzipiert und leitet die eingehenden Anfragen an die entsprechenden Module weiter.
  \item \textbf{Sicherheit}: Das Gateway führt eine initiale Rechteprüfung durch, hierbei prüft es den vom lokalen Backend übergebenen Nutzungsschlüssel auf Gültigkeit. Bei erfolgreicher Prüfung wird vom Gateway ein neues JSON-Web-Token (JWT) generiert, welches für die interne Kommunikation mit den Modulen verwendet wird.
\end{itemize}
Durch dieses Design sind die einzelnen Module von der Kommunikation von außen entkoppelt. 
Zur Qualitätssicherung dieser Implementierung führte ich eine Reihe von End-to-End-Tests durch. Unter Verwendung des API-Clients Bruno teste ich den gesamten Datenfluss vom lokalen Backend zum Gateway und anschließend zum Phishing-Modul. Um realistische Bedingungen zu testen, entwickelte ich ein Python-Skript für Lasttests, welches zehn gleichzeitige Anfragen an unsere Backends ausführen kann. Dabei identifizierte ich das Problem, dass unser Mistral Agent bei zu vielen zeitgleichen Anfragen mit dem Status Code 429 (Too Many Requests) abbrach. Nach eingehender Recherche wurde festgestellt, dass unser kostenloser Studententarif lediglich zwei gleichzeitige Aufrufe erlaubt. Wir entschieden uns teamintern in der Entwicklungsphase diesen Tarif zunächst nicht zu erweitern. Um auf die identifizierten Msitral-Api Beschränkungen professionell zu reagieren, brachte ich zwei Änderungen an dem Aufruf der Mistral-Api ein:
\begin{itemize}
  \item \textbf{Explizites Error-Handling mit Retry-Logik}: Das Backend wurde so erweitert, dass es auf den Fehlercode 429 gezielt reagiert. Bei Auftreten des Fehlercodes wird automatisch ein neuer Versuch eingeleitet (bis zu maximal drei Versuchen). 
  \item \textbf{Concurrency-Control mittels Semaphoren}: Zusätzlich habe ich einen Semaphore implementiert. Dieser limitiert die Anzahl der gleichzeitig ausgehenden Anfragen an die Mistal-API auf maximal zwei Threads. Überzählige Anfragen werden in eine Warteschlange gesetzt.
\end{itemize}
Zum Abschluss des Sprints gab uns Tom nochmal Einblicke in die Umsetzung des Deployments mittels Plesk. Ich empfand diesen Austausch als wirklich interessant und wertschöpfend, da ich bisher Deploys immer dierkt über GitHub oder Jenkins gemacht hatte. Ich unterstütze den Prozess, indem ich entsprechenden Weebhooks in unsern GitHub-Repositories konfigurierte. Im abschließenden Review wurden alle Anpassungen präsentiert und diskutiert. Die abschließende Retrospektive unterstrich die positive Dynamik in der Projektgruppe. Das Team funktioniert gut, die Kommunikation ist effizient und alle Aufgaben wurden zielgerichtet erledigt.
\section{Sprint 4 27.06.2025.03.2025 bis 25.07.2025}
Der Sprint startete mit unserem Planning am 27.06.2025. Im Fokus stand die vollständige Implementierung des Datenbankmodells in das lokale Backend. Darüber hinaus wollten wir zum Verwalten der Datenbankeinträge Schnittstellen bereitstellen (CRUD Operationen). Ein weiterer Meilenstein in diesem Sprint war für uns der echte Mailversand und die draus resultierende Erstellung und Persistierung der Kampagne. 
Eine Kampagne stellt eine eingestände Entität in unserer Datenbank dar. Eine Kampagne fungiert als eine Oberklasse, die die eigentliche Mail, alle Konfigurationsparameter und dynamische Werte zur Kampagne wie Klickrate oder den Status hält.
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.8\textwidth]{figures/DbModell.png} 
    \caption{Das fertige Datenmodell im Lokalen Backend}
    \label{fig:architektur}
\end{figure}
Für mich begann der Sprint mit Performance-Optimierung bei der Mailerstellung. Im Rahmen von iterativen Tests ermittelte ich, dass die realtiv hohen Durchlaufzeiten beim Erstellen von Mails auf die Verarbeitungszeit der generativen KI (Mistral AI) zurückzuführen ist. Daraus ergab sich für mich eine zentrale architektonische Problemstellung, denn ein Srpingbackend nutzt in der Regel ein Thread-per-Request-Modell (Tomcat). Das heißt, dass für jeden Aufruf ein Thread zugewiesen wird. Das Problem ist, dass diese Threads als teuer gelten, da sie direkt an Systemressourcen gebunden sind. Bei steigender Last besteht hier die Gefahr, dass es zu einem Thread-Starvation kommen kann. Hierbei wäre der Service nicht mehr erreichbar, weil alle Threads zurzeit auf eine KI-Antwort warten, ohne dabei (und das ist wichtig) tatsächlich die ihnen zugewiesene Rechenleistung zu nutzen. Wir könnten in diesem Szenario dann nur durch mehr Serverinstanzen oder durch einen größeren Threadpool pro Instanz skalieren, obwohl das eigentlich gar nicht nötig wäre, da unsere Kapazitäten gar nicht genutzt, sondern nur durch Warten blockiert werden.
Ich erarbeite drei Ansätze um mit dieser Problemstellung umzugehen:
\begin{itemize}
  \item \textbf{Akzeptanz und Fehlertoleranz}: Bei diesem Ansatz würde das bestehende Modell beibehalten und das Fehlerhandling optimiert.
  \begin{itemize}
  \item \textbf{Vorteil}: kein Implementierungsaufwand und keine erhöhte Codekomplexität
  \item \textbf{Nachteil}: Bei hoher Last besteht die Gefahr, dass der Service nicht mehr erreichbar ist beziehungsweise nur teuer skaliert werden kann.
  \end{itemize}
  \item \textbf{Reaktives Programmiermodell (Spring WebFlux)}: Bei diesem Ansatz würden wir von einem imperativen Modell auf ein reaktives umstellen. Bei einem reaktiven Programmiermodell sind die Threads nicht fest an den Anfragen gebunden, sondern reagieren auf tatsächliche Ereignisse.
    \begin{itemize}
  \item \textbf{Vorteil}: extrem gute Ressourceneffizienz selbst bei vielen Anfragen
  \item \textbf{Nachteil}: Die Codebasis müsste vollständig umgeschrieben werden, da hier keine blockierenden Codeteile mehr vorhanden sein dürfen. Dies würde auch alle extern eingebundenen Bibliotheken betreffen. Zudem würde dies die Komplexität massiv erhöhen, was das Debugging und die Einarbeitung des Teams behindern würde.
  \end{itemize}
    \item \textbf{Virtual Threads}: Seit Java 21 gibt es die Möglichkeit, Threads zu virtualisieren. Hierbei würden wir die blockierenden Aufrufe akzeptieren, aber die Threads sehr günstig machen, da wir diese von den echten Systemkapazitäten entkoppeln.
      \begin{itemize}
  \item \textbf{Vorteil}: Aus wenigen physischen Threads können Millionen leichtgewichtige virtuelle Threads entstehen. Die Codebasis bleibt weitesgehend gleich.
  \item \textbf{Nachteil}: Virtuelle Threads erhöhen nicht die Rechenleistung. Sie bieten sich daher nicht für rechenintensive Anwendungen an.
  \end{itemize}
\end{itemize}
Ich stellte diese Punkte unserem Workstream-Team vor und gemeinsam einigten wir uns auf den Einsatz von Virtual Threads, da sie unser Problem lösen, ohne die Architektur grundlegend zu verändern. 
Im Laufe dieses Sprint implementiere ich weitestgehend in Pair- und Mob-Programming-Sessions das Datenbankmodell in das lokale Backend. Das heißt, wir legten die entsprechenden Klassen in Java an und bauten die entsprechenden Services für den Zugriff auf die MongoDB. Darüber hinaus implementierten wir einen Controller, der die vereinbarten Schnittstellen zur Verfügung stellt. Wir banden im nächsten Schritt diese Schnittstellen auch aus dem Frontend an. Es war nun erstmalig möglich, im Frontend Daten aus dem Backend zu verwalten.
In weiteren Pair- und Mob-Programming-Sessions setzten wir die Versandfunktionalität um. Hierbei hinterlegten wir für die Testphase unseren eigenen Mailserver. Im Produktivbetrieb ist es so gedacht, dass der Anwender bei der Installation seinen Mailserver als Umgebungsvariable mitgibt. Zum Versenden der HTML-Mails setzen wir auf Springmail in Kombination mit MimeMessage. Unmittelbar vor dem Versand erfolgt eine dynamische Personalisierung mit Anrede und Titel. Um Fehlsendungen und Missbrauch vorzubeugen, ist es während unserer Proof-of-Concept-Phase nur möglich, echte Mails an Empfänger einer festgelegten Testliste herauszuschicken.  Alle anderen Sendevorgänge werden lediglich im System geloggt. Nach dem erfolgreichen Versenden der Mails wird eine neue Kampagnen-Entität in der Datenbank gespeichert. Diese speichert unter andrem die Referenzen (ID) der Empfänger, um später das Interaktionsverhalten nachverfolgen zu können. 
Nun war es uns möglich, auch erstmalig den End-to-End-Workflow zu durchlaufen vom Anlegen der Empfängerlisten bis zum finalen Versand der Mails.
Der Sprint endete mit unserer Review und unserer Retrospektive am 25.07.2025. Im Rahmen der Review präsentierten wir unsere Fortschritte. Ich ging hier zum Beispiel nochmal explizit auf die Virtual Threads ein, die eingebaut wurden. Die Retrospektive zeigte, dass unser Projektteam weiterhin hoch motiviert ist und äußerst gut zusammenarbeitet.
\section{Sprint 5 25.07.2025 bis 19.09.2025}
Dieser Sprint begann mit unserem Planning Vorort in der OHM-Professional-School am 25.07.2025. Aufgrund von geplanter Urlaubszeiten in unserem Projektteam reduzierten wir das Volumen der geplanten Features bewusst, um auf diese Situation zu reagieren. Als Workstreamgruppe setzen wir in diesem Sprint darauf, die bestehenden Platzhalter in den generierten E-Mails durch trackbare Links zu ersetzen. Darüber hinaus nahmen wir uns noch vor, den Wizard um einen initialen Step zu erweitern, indem der Anwender die Kampagnenrahmendaten erfassen muss.
Die Implementierung der trackbaren Links fand wie viele der Kernfeatures des Phishing-Moduls im Rahmen einer Mob-Session statt. Wichtig war es hier, dass für jeden Empfänger ein Link erstellt wird, um die Klicks personenbezogen nachvollziehen zu können. Technisch wählten wir hierfür die Codestelle, in der wir schon die Anrede und den Titel individualisieren. Der Link, der zur Laufzeit erstellt wird, zeigt auf einen GET-Endpunkt in unsern Backend, wobei eine eindeutige GUID als Pfadparameter übergeben wird. Wenn der Endpunkt aufgerufen wird, wird ein entsprechender Eintrag mit der GUID in der Kampagne hinterlegt. Dies bot uns die Möglichkeit, diese Daten dann später für Auswertungszwecke dem Frontend zur Verfügung zu stellen. 
Ergänzend zur Mailverfolgung untersuchte ich Möglichkeiten, um das Öffnen der Mails im Mailprogramm nachverfolgen zu können. Technisch erwies sich das als Herausforderung, daher entwickelte ich einen Proof of Concept. Ich bette in jede verschickte HTML-Email ein sogenanntes "Trackingpixel" (1x1-Bild) mit ein. Dieses Bild soll dann über einen Restaufruf ans Backend nachgeladen werden. Auch hier dient die individuelle GUID als Parameter im Link, um den Aufruf zuzuordnen zu können. Sobald im Mailprogramm die Mail geöffnet wird, wird der Aufruf verschickt. Ein großer Nachteil an diesem Ansatz ist, dass viele moderne Email-Clients standardmäßig das Nachladen von Bildern blockieren. Dies schränkt die Zuverlässigkeit dieses Ansatzes ein. Gemeinsam in der Projektgruppe haben wir dann entschieden, das Feature beizubehalten, um tendenziell die Möglichkeit zu bieten, die Öffnungsraten nachverfolgen zu können. Auf Basis dieser Entscheidung brachte ich nach einem umfangreichen Code-Review meinen Entwicklungsbranch mit diesem Feature in unseren Hauptbranch ein. Im weiteren Verlauf dieses Sprints, behob ich verschiedene Probleme beim Aufruf und Löschen von Empfängerlisten. Ein kritischer Fehler war dabei, dass beim Löschen einer Empfängerliste alle in ihr vorkommenden Empfänger gelöscht wurden, ohne das geprüft wurde, ob die Empfänger noch in anderen Empfängerlisten verwendet wurden. Um diesen Fehler zu beheben, baute ich vor dem endgültigen Löschen der Empfänger eine Prüfung ein, die alle aktiven Empfängerlisten nach den zu löschenden Empfängern prüft. In dem Fall, dass ein Empfänger bei der Prüfung in einer andern aktiven Empfängerliste vorkommt, wird dieser Empfänger nicht gelöscht. Darüber hinaus nahm ich noch weitere Anpassungen an dem Hinzufügen und Löschen von Empfängerlisten im Frontend vor. Die Anpassungen fanden primär in der Typeskript-Logik und der Kommunikation zwischen Backend und Frontend statt. Zum Beispiel band ich die entsprechenden Endpunkte des Backends im Frontend an und wertete diese aus. Vor Abschluss dieses Sprintes entwickelten wir in einer weiteren Mob-Sessions den initialen Step beim Anlegen einer Phishing-Kampagne. Der Hauptteil der Arbeit lag im Frontend und in der Übergabe der neuen Daten ins Backend. Im Backend wurden lediglich die Datenobjekte erweitert. 
Der Sprint endete mit der Retrospektive und dem Review. Beim Review wurden wie immer die Ergebnisse des Sprints vorgestellt und kritisch hinterfragt. Wir stellten hier den Workflow rund um die Empfängerlisten vor. In der Retrospektive zeigte sich, dass das Projektteam grundsätzlich zufrieden ist, aber Verbesserungspotenziale in der Kommunikation sieht. Die eingeschränkte Kommunikation in diesem Sprint, war aber auch auf die Urlaubssituation zurückzuführen. Dennoch nahmen wir uns vor, im nächsten Sprint auf eine klarere Kommunikation zu achten. 
\section{Sprint 6 19.09.2025 bis 24.10.2025}
Bei unserem Planning vor Ort am 19.09.2025 lag unser Fokus primär darauf, den bestehenden Code zu refactoren und auf der Behebung von offenen Bugs. Aufgrund des verhältnismäßig kurzen Sprints nahm ich mir vor, um noch genug Zeit für die Klausurvorbereitungen zu haben, relativ früh im Sprint meinen Beitrag zu leisten. Das Refactoring fand im Rahmen von Mob-Sessions statt. Dies war uns besonders wichtig, um sicherzustellen, dass unsere Codebasis von jedem Workstreammitglied eigenständig gewartet werden kann. Beim Refactoring konzentrierten wir uns drauf, den Code lesbarer und sauberer zu gestalten. Wir orientierten uns dabei an Industriestandards. Als Orientierung dienten uns hierbei unter anderem die objektorientierten Patterns der "Gang of Four" (vgl. \cite{gamma1994design}). Uns war es wichtig, die Komplexität der einzeln Methoden soweit zu reduzieren, dass jeder Entwickler sie ohne eine umfassende Einarbeitung warten kann. Die Anzahl der einzelnen If-Cases und die Methoden sowie die Klassenlänge waren dafür wichtige Indizien. Weiterhin setzen wir auf eine klare und einheitliche Namensgebung unserer Klassen, Methoden und Variablen. Aus den Namen soll immer der eigentliche Zweck des jeweiligen Objekts ersichtlich sein. JSON-Parameter werden im "Snake-Case" notiert und normale Variablen, Methoden und Klassen unter Berücksichtigung der Java-Standards im "Camel-Case". Im weiteren Verlauf des Sprints lag der Fokus auf der Behebung von Bugs. Ein kritischer Fehler war das Fehlen eines Rollbacks, wenn das Versenden der E-Mails auf einen Fehler gelaufen ist. In diesem Szenario wurde trotzdem das Kampagnen-Objekt in der Datenbank angelegt, obwohl keine Mails versandt wurden. Das Erstellen der Kampagnen-Objekte findet im technischen Ablauf vor dem Versenden der Mails statt, da wir beim Versenden der Mails die Kampagnen-ID mit in den Link schreiben, um die Klicks zuordnen zu können. Den Bug konnte ich durch gezieltes Fehlerhandling beheben. Schlägt der Versand der E-Mails fehl, wird gezielt ein Rollback ausgeführt. Hierfür setze ich auf eine kompakte Try- und Catch-Logik. 
\begin{figure}[H]
    \centering
    % Hier wird der Pfad zum Ordner "figures" angegeben
    \includegraphics[width=0.7\textwidth]{figures/testpr.jpg} 
    \caption{Testpyramide Fokus Backendservices (Bild KI-generiert)}
    \label{fig:architektur}
\end{figure}
Zum Abschluss des Sprints erarbeite ich ein Testkonzept für unsere Backends. Mein Ziel war es, für die bestehenden Backends eine ganzheitliche Teststrategie zu etablieren.
\begin{itemize}
  \item \textbf{Unit-Tests}: Unittests bilden das Fundament unserer Teststrategie. Sie wurden fortlaufend während der Entwicklung bevorzugt testdriven implementiert. Sie testen alle  Methoden vollständig isoliert.
  \item \textbf{Integrationstest}: Integrationstests testen den Workflow innerhalb eines Services. Hier wird die Zusammenarbeit zwischen verschiedenen Komponenten des Services getestet.
    \item \textbf{Contract-Tests}: Diese Tests können als Vertragstests zwischen zwei Schnittstellenpartnern angesehen werden. Sie sollen in erster Linie "Breaking Changes" verhindern. Dies stellt sicher, dass Änderungen an einem Service nicht die Lauffähigkeit abhängiger Partner-Services beeinträchtigen.
    \item \textbf{End-to-End-Tests}: Sie stellen einen automatisierten Durchlauf des kompletten Benutzerflusses dar. Sie können auch als eine Art automatisierter Abnahmetest angesehen werden. Sie stellen sicher, dass die Geschäftslogik aus Anwendersicht funktioniert. 
\end{itemize}
Der Sprint endete am 24.10.2025 mit unser Review und unserer Retrospektive vor Ort in Nürnberg. Im Rahmen der Review stellte ich dem gesamten Projektteam das von mir erstellte Testkonzept vor. Wir einigten uns darauf, im nächsten Sprint die zusätzlichen Tests zu implementieren. 
In der Retrospektive zeigte sich das Team immer noch als äußert motiviert und produktiv. 
\section{Sprint 7 24.10.2025 bis 05.12.2025}
Unser Sprint startete mit dem Planning am 24.10.2025 vor Ort in Nürnberg. Fokus lag in diesem Sprint auf dem Abschluss der Feature-Entwicklung. Unser Ziel war es, Voraussetzungen zu schaffen, die es uns erlauben, uns im darauffolgenden Sprint auf den Bugabbau und die Verbreitung der Präsentationen zu konzentrieren. 
Relativ früh im Sprint traf sich unsere Workstreamgruppe persönlich vor Ort in Nürnberg, um gemeinsam die finalen Features im Phishing-Modul zu implementieren. Im Rahmen eines intensiven Workshop-Samstags (10 Uhr bis 20 Uhr) implementieren wir die noch offenen Features für das Modul. Diese Präsenztreffen nahm ich stets als besonders produktiv und konstitutiv wahr. Ein Highlight dieses Samstags war unter anderem die Implementierung einer Zugstimmungsseite, die der erstmaligen Nutzung des Phishing-Moduls vorgeschaltet ist. Die Steuerung erfolgt über ein Flag in der Datenbank:
\begin{itemize}
    \item \textbf{Backend-Logik}: Über einen Endpunkt wird geprüft, ob der Nutzer den Nutzungsbedingungen schon zugestimmt hat. Hierbei wird zur Bestimmung des Nutzers der Auth-Header aufgelöst, um den Status aus der Datenbank abzufragen.
    \item \textbf{Frontend-Logik}: Basierend auf diesen Informationen wird der Anwender entweder direkt zu dem Modul weitergeleitet oder zur Bestätigung der Nutzungsbedingungen aufgefordert. Sobald der Nutzer den Bedienungen zugestimmt hat, wird die Flag in der Datenbank gesetzt.
\end{itemize}
Ich nahm mir für diesen Sprint weiterhin das ambitionierte Ziel vor, die Teststrategie im Backend weitestgehend zu implementieren. Neben den bereits während der Entwicklung bevorzugt testgetriebenen implementierten Unit-Tests nahm ich mir vor, Integrationstest, Contract-Test und End-to-End-Tests zu entwickeln. Wichtig bei den Integrationstests war, dass sie in den Mirkoservices selbst keine Abhängigkeiten mocken, sondern die tatsächlichen Implementierungen aufgerufen werden. Die Integrationstests wurden technisch als Unit-Tests mit größeren Scope gebaut. Um ein realistisches Verhalten der Datenbank zu erhalten, ohne diese zu mocken, wird die Bibliothek Testcontainers eingesetzt. Diese ermöglicht es, während der Testlaufzeit isolierte Dockercontainer hochzufahren und mit bestimmter Software zu bestücken. Nach Abschluss des Tests werden diese Container wieder verworfen. Damit die Tests lokal ausführbar bleiben, braucht es lokal einen Container mit der Datenbank. Dafür setzte ich auf Podman, der die Container bereitstellen kann. In der CI/CD-Pipline (GitHub Actions) werden diese Tests ebenfalls mithilfe von Containern ausgeführt (vgl. \cite{podman2025, testcontainers2025}). Für die Contract-Tests setzte ich auf PACT. Mit PACT hatte ich bereits im Rahmen meiner beruflichen Tätigkeit positive Erfahrungen gemacht. PACT wird eingesetzt, um Interaktionen zwischen Schnittellenpartnern verbindlich über sogenannte Pacts zu definieren. Dies hilft dabei, nicht beabsichtige Breakingchanges zu verhindern (vgl. \cite{pact2025docs}). 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/pact.png} 
    \caption[Pact Ablauf]{Pact Ablauf (Quelle: \cite{pact_docs})}
    \label{fig:architektur}
\end{figure}
Der grundsätzliche Gedanke ist es, dass Consumer und Provider sich auf einen PACT (Contract) einigen und dagegen testen. Sobald einer der beiden eine Änderung einbringt, die den Contract verletzt, laufen die Tests auf einen Fehler. Bei unseren Pacttests konzentrierte ich mich primär auf die Verbindungen von dem Lokal-Backend zu unseren Modulen. Das liegt daran, dass wir nach der Auslieferung unser OnPremise-Software nicht mehr so leichtgewichtig Änderungen einbringen können, wie wir es in einer Cloud-Umgebung machen können. Fehler, die die Contracts zwischen den Backends verletzen, können sehr teuer werden im produktiven Betrieb. Aufgrund unser limitieren finanziellen Ressourcen erstellte ich den PACT durch einen  "Consumertest" und speicherte anschließend das generierte "PACT-File" in die jeweiligen Modul-Backends ab. Es gibt PACT-Brooker wie PactFlow, die einem diese Arbeit abnehmen, indem sie die Pacts zentral verwalten, allerdings sind diese Lösungen relativ kostspielig und ich habe bewusst drauf verzichtet, diese in unsere Services einzubinden. 
Mit den Unittests, Integrationstest sowie den Pacttests sind die rein backendsseitigen Tests der Teststrategie von mir in diesem Sprint implementiert worden. Die End-to-End-Tests nahm ich mir vor, zwischen den Jahren in das Frontend zu implementieren. In den Backends kommen wir auf eine Codecoverage von ungefähr 90 Prozent.
Der Sprint endete mit unser Review und unser Retrospektive am 05.12.2025. In der Review stellte ich die implementierten Tests vor. Wir konnten die meisten der offen Features erledigen, sodass wir uns im finalen Sprint nur noch mit dem Bugabbau beschäftigen konnten. 
\section{Sprint 8 05.12.2025 bis 26.02.2026}
Der finale Sprint begann am 5.12.2025 wieder vor Ort in Nürnberg mit unserem Planning. Im Fokus dieses Sprintes stand der Bugabbau. Wir nahmen uns darüber hinaus vor, keine produktiven Erweiterungen in das System mehr einzubringen und ab Ende Januar keine Changes mehr im Code einzubringen, um sicherzustellen, dass wir bei den Präsentationen im Februar eine funktionsfähige Software vorzeigen können. Ein besonderes Event in diesem Sprint war, dass unser Auftrageber Dr. Dirk Kötting persönlich vor Ort war. Wir nutzen seinen Anwesenheit für einen Usability-Test unserer Anwendung, den wir mit ihm ausführten. Unser Produkt Owner Christian Langer hatte dahingehend die nötigen Vorbereitungen getroffen. Meine Aufgabe hierbei war es, Dr. Dirk Kötting zu beobachten und Notizen zu machen, inwieweit er intuitiv die Anwendung bediente. Die hieraus resultierenden Erkenntnisse erfassten wir als Bugs. In diesem Sprint beschäftigte ich mich abschließend mit dem Einbau von End-to-End-Tests, um unseren Modul-Workflow komplett zu testen. Es gibt eine Reihe von Frameworks und Tools, die einem bei diesen Tests unterstützen. Nach intensiver Recherche entschied ich mich dafür, Playwright zu nutzen. Playwright bietet die Möglichkeit, moderne Browser automatisiert zu steuern. Es bietet dem Anwender die Möglichkeit, seine spezifischen Workflows automatisiert und performant zu testen(vgl. \cite{playwright2025docs}). Die Implementierung erwies sich als äußert intuitiv und einfach. Nach kurzer Eingewöhnungszeit war es mir möglich, umfangreiche Playwright-Tests zu bauen, die die Prozesse des Anwenders realistisch darstellen. 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/playwright beispiel.png} 
    \caption{Ausschnitt aus den Playwright Tests}
    \label{fig:architektur}
\end{figure}